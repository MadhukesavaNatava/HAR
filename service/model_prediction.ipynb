{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25fea8d5-b7f7-4c7a-b7b8-ae7f6ab1c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e0ad87-804e-4cfd-b58f-3746fa06351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../model/HAR_CNN.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d5af7e-d514-48d7-8cd7-6c3d20889966",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {0: 'clapping', 1: 'dancing', 2: 'laughing', 3: 'running'}  # Update based on your label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b26746-b9f9-4453-964c-898a6a0af8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_size = 0.2  # Percentage of data for the test set\n",
    "val_size = 0.15   # Percentage of remaining data for validation set\n",
    "random_seed = 42  # For reproducibility\n",
    "img_size = (64, 64)  # Image dimensions\n",
    "num_classes = 4  # Number of classes (e.g., clapping, dancing, laughing, running)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe57829-6f3c-4388-b210-02b309d45534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Load the image in grayscale\n",
    "    img = load_img(image_path, target_size=img_size, color_mode='grayscale')\n",
    "    # Convert to array and normalize\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    # Add batch dimension\n",
    "    return np.expand_dims(img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af049bf-7e8c-4e37-8a44-e8a394a30e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make prediction\n",
    "def predict_action(image_path):\n",
    "    #model = joblib.load('path/to/your/model') \n",
    "    # Preprocess the image\n",
    "    preprocessed_img = preprocess_image(image_path)\n",
    "    # Predict the class probabilities\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    # Get the class with the highest probability\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_class_label = label_mapping[predicted_class_index]\n",
    "    # Return the predicted label and probability\n",
    "    return predicted_class_label, predictions[0][predicted_class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f64032c-d3ab-4ae4-a310-7b833934be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701ms/step\n",
      "Predicted Action: running\n",
      "Confidence: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "image_path = '../data/test-mg/Image_31.jpg'\n",
    "predicted_label, confidence = predict_action(image_path)\n",
    "print(f\"Predicted Action: {predicted_label}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00495284-b9d4-432f-b0af-7af70bc8a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0a5402a-fe4b-463e-8462-b1df60d5198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully with tags: ['train']\n",
      "Error during prediction: 'serving_default'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to load the saved I3D model with appropriate tags\n",
    "def load_i3d_model(model_dir, tags=['train']):\n",
    "    \"\"\"\n",
    "    Load the I3D model with specified MetaGraph tags.\n",
    "    - model_dir: Path to the directory containing the SavedModel.\n",
    "    - tags: Tag set to specify the MetaGraph ('serve' for inference).\n",
    "    \"\"\"\n",
    "    model = tf.compat.v1.saved_model.load_v2(model_dir, tags=tags)\n",
    "    print(f\"Model loaded successfully with tags: {tags}\")\n",
    "    return model\n",
    "\n",
    "# Function to preprocess the input for I3D\n",
    "def preprocess_input(video_frames, target_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess the input video frames.\n",
    "    - Resize frames to the target shape.\n",
    "    - Normalize pixel values to [0, 1].\n",
    "    \"\"\"\n",
    "    preprocessed_frames = [\n",
    "        tf.image.resize(frame, target_shape) / 255.0 for frame in video_frames\n",
    "    ]\n",
    "    return tf.convert_to_tensor(preprocessed_frames, dtype=tf.float32)\n",
    "\n",
    "# Generate dummy input (replace this with actual video frames)\n",
    "def generate_dummy_video(num_frames=32, height=224, width=224, channels=3):\n",
    "    \"\"\"\n",
    "    Generate a dummy video with random pixel values.\n",
    "    - num_frames: Number of frames in the video.\n",
    "    - height, width: Frame dimensions.\n",
    "    - channels: Number of channels (e.g., RGB).\n",
    "    \"\"\"\n",
    "    return np.random.rand(num_frames, height, width, channels).astype(np.float32)\n",
    "\n",
    "# Load the model\n",
    "model_dir = \"../model/i3d\"  # Replace with the path where your saved_model.pb is located\n",
    "i3d_model = load_i3d_model(model_dir, tags=['train'])  # Specify 'serve' tag for inference\n",
    "\n",
    "# Prepare dummy video input (32 frames, 224x224 resolution, RGB)\n",
    "#video_input = generate_dummy_video()\n",
    "\n",
    "video_path = '../data/party1.mp4'\n",
    "# Preprocess the input video\n",
    "preprocessed_video = preprocess_input(video_input)\n",
    "\n",
    "# Add batch dimension (batch_size=1)\n",
    "input_tensor = tf.expand_dims(preprocessed_video, axis=0)\n",
    "\n",
    "# Make a prediction\n",
    "try:\n",
    "    prediction = i3d_model.signatures[\"serving_default\"](input_tensor)\n",
    "    print(\"Prediction results:\")\n",
    "    print(prediction)\n",
    "except Exception as e:\n",
    "    print(\"Error during prediction:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9bd7126-6528-4f46-906e-a9aa9c45593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully with tags: {'train'}\n",
      "Available signatures:\n",
      "_SignatureMap({'default': <ConcreteFunction () -> Dict[['default', TensorSpec(shape=(None, 400), dtype=tf.float32, name=None)]] at 0x2698DC3E290>})\n",
      "Top Predictions:\n",
      "celebrating: 0.2188\n",
      "dancing macarena: 0.0520\n",
      "country line dancing: 0.0432\n",
      "belly dancing: 0.0278\n",
      "headbanging: 0.0271\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to load class labels\n",
    "def load_labels(label_file):\n",
    "    \"\"\"\n",
    "    Load class labels from a label map file.\n",
    "    - label_file: Path to the file containing labels.\n",
    "    \"\"\"\n",
    "    with open(label_file, \"r\") as f:\n",
    "        labels = [line.strip() for line in f.readlines()]\n",
    "    return labels\n",
    "\n",
    "# Assuming 'prediction' is the output from the model\n",
    "def get_top_predictions(prediction, labels, top_k=5):\n",
    "    \"\"\"\n",
    "    Map the model's numeric predictions to human-readable labels.\n",
    "    - prediction: Model output array (e.g., logits or probabilities).\n",
    "    - labels: List of class labels.\n",
    "    - top_k: Number of top predictions to return.\n",
    "    \"\"\"\n",
    "    # Convert predictions to probabilities if needed (e.g., softmax)\n",
    "    probabilities = tf.nn.softmax(prediction).numpy()\n",
    "\n",
    "    # Get top-k predictions\n",
    "    top_indices = np.argsort(probabilities[0])[::-1][:top_k]\n",
    "    top_predictions = [(labels[i], probabilities[0][i]) for i in top_indices]\n",
    "\n",
    "    return top_predictions\n",
    "\n",
    "# Function to preprocess input for I3D\n",
    "def preprocess_input(video_frames, target_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess input video frames:\n",
    "    - Resize frames to the target shape.\n",
    "    - Normalize pixel values to [0, 1].\n",
    "    \"\"\"\n",
    "    preprocessed_frames = [\n",
    "        tf.image.resize(frame, target_shape) / 255.0 for frame in video_frames\n",
    "    ]\n",
    "    return tf.convert_to_tensor(preprocessed_frames, dtype=tf.float32)\n",
    "\n",
    "# Function to load video file and convert to frames\n",
    "def load_video(file_path, max_frames=32, resize_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    Load a video from the file path, extract frames, and preprocess them.\n",
    "    - file_path: Path to the video file.\n",
    "    - max_frames: Maximum number of frames to load from the video.\n",
    "    - resize_shape: Tuple specifying the frame dimensions (height, width).\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened() and frame_count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Convert frames to tensor and preprocess\n",
    "    frames_tensor = preprocess_input(frames, target_shape=resize_shape)\n",
    "    return frames_tensor\n",
    "\n",
    "# Load the model\n",
    "def load_i3d_model(model_dir, tags={'train'}):\n",
    "    \"\"\"\n",
    "    Load the I3D model with specified MetaGraph tags.\n",
    "    - model_dir: Path to the directory containing the SavedModel.\n",
    "    - tags: Tag set to specify the MetaGraph.\n",
    "    \"\"\"\n",
    "    model = tf.compat.v1.saved_model.load_v2(model_dir, tags=tags)\n",
    "    print(f\"Model loaded successfully with tags: {tags}\")\n",
    "    return model\n",
    "\n",
    "# Main script\n",
    "model_dir = \"../model/i3d/\"  # Replace with your model directory path\n",
    "video_path = \"../data/party4.giff\"  # Replace with your local video file path\n",
    "\n",
    "# Load the model\n",
    "i3d_model = load_i3d_model(model_dir, tags={'train'})\n",
    "\n",
    "# Load and preprocess the video\n",
    "video_tensor = load_video(video_path)\n",
    "\n",
    "# Add batch dimension (batch_size=1)\n",
    "input_tensor = tf.expand_dims(video_tensor, axis=0)\n",
    "\n",
    "# Path to the label file\n",
    "label_file = \"../model/i3d/label_map.txt\"  # Replace with the path to your labels file\n",
    "\n",
    "# Load labels\n",
    "labels = load_labels(label_file)\n",
    "\n",
    "# Perform prediction\n",
    "try:\n",
    "    print(\"Available signatures:\")\n",
    "    print(i3d_model.signatures)\n",
    "\n",
    "    # Example prediction (replace 'your_signature_key' with the correct key)\n",
    "    signature_key = list(i3d_model.signatures.keys())[0]\n",
    "    raw_prediction = i3d_model.signatures[signature_key](input_tensor)\n",
    "\n",
    "    # Map predictions to class labels\n",
    "    top_predictions = get_top_predictions(raw_prediction['default'], labels)\n",
    "    print(\"Top Predictions:\")\n",
    "    for label, score in top_predictions:\n",
    "        print(f\"{label}: {score:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during prediction:\", str(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124e494-a2a6-46ea-b75d-7bd794c7a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model loaded successfully with tags: {'train'}\n",
    "Available signatures:\n",
    "_SignatureMap({'default': <ConcreteFunction () -> Dict[['default', TensorSpec(shape=(None, 400), dtype=tf.float32, name=None)]] at 0x269859F6290>})\n",
    "Top Predictions:\n",
    "celebrating: 0.2601\n",
    "dancing macarena: 0.0443\n",
    "pumping fist: 0.0297\n",
    "headbanging: 0.0274\n",
    "robot dancing: 0.0272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ea0b7-ea2a-4efc-aefd-6d29120e2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrating: 0.1806\n",
    "marching: 0.0548\n",
    "dancing macarena: 0.0476\n",
    "dancing gangnam style: 0.0379\n",
    "pumping fist: 0.0325"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
